{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.0 Data Scrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "#Encontrando o html dos produtos\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "products = soup.find('ul', class_ = 'products-listing small')\n",
    "products_list = products.find_all('article', class_= 'hm-product-item')\n",
    "\n",
    "\n",
    "#Product id\n",
    "product_id = [p.get('data-articlecode') for p in products_list]\n",
    "\n",
    "\n",
    "#Product Category\n",
    "product_category = [p.get('data-category') for p in products_list]\n",
    "\n",
    "#Product name\n",
    "products_list = products.find_all('a', class_= 'link')\n",
    "product_name = [p.get_text() for p in products_list]\n",
    "\n",
    "#Price\n",
    "price_list = products.find_all('span', class_= 'price regular')\n",
    "product_price = [ p.get_text() for p in price_list]\n",
    "product_price\n",
    "\n",
    "data = pd.DataFrame([product_id, product_category, product_name,  product_price]).T\n",
    "data.columns = ['product_id', 'product_category', 'product_name', 'product_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.0 Data Collection by Product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "# empty dataframe\n",
    "aux_compositions = ['Art. No.', 'Composition', 'Fit', 'Product safety', 'Size', 'More sustainable materials']\n",
    "df_compositions = pd.DataFrame()\n",
    "# unique columns for all products\n",
    "aux = []\n",
    "cols = ['Art. No.', 'Composition', 'Fit', 'Product safety', 'Size', 'More sustainable materials']\n",
    "df_pattern = pd.DataFrame( columns=cols )\n",
    "for i in range( len( data ) ):\n",
    "    \n",
    "    # API Requests\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id']+ '.html'\n",
    "    page = requests.get( url, headers=headers )\n",
    "    \n",
    "    # Beautiful Soup object\n",
    "    soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "    \n",
    "    # ==================== color name =================================\n",
    "    product_list = soup.find_all( 'a', class_='filter-option miniature' ) + soup.find_all( 'a', class_='filter-option miniature-active' )\n",
    "    color_name = [p.get( 'data-color' ) for p in product_list]\n",
    "    \n",
    "    \n",
    "    # product id\n",
    "    product_id = [p.get( 'data-articlecode' ) for p in product_list]\n",
    "    df_color = pd.DataFrame( [product_id, color_name] ).T\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "    \n",
    "    for j in range(len(df_color)):\n",
    "        # API Requests\n",
    "        url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[j,'product_id'] + '.html'\n",
    "        #print( 'Color: {}'.format( url ) )\n",
    "        page = requests.get( url, headers=headers )\n",
    "        # Beautiful Soup object\n",
    "        soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "        # ================ Product Name ============================\n",
    "        product_name = soup.find_all( 'h1', class_='primary product-item-headline' )\n",
    "        product_name = product_name[0].get_text()\n",
    "        \n",
    "        # ================ Product Price ============================\n",
    "        product_price = soup.find_all( 'div', class_='primary-row product-item-price' )\n",
    "        product_price = re.findall( r'\\d+\\.?\\d+', product_price[0].get_text())[0]    \n",
    "\n",
    "        # ==================== composition =================================\n",
    "        product_composition_list = soup.find_all( 'div', class_='pdp-description-list-item' )\n",
    "        product_composition = [list( filter( None, p.get_text().split( '\\n' ) ) ) for p in product_composition_list]\n",
    "        \n",
    "        # rename dataframe\n",
    "        df_composition = pd.DataFrame( product_composition ).T\n",
    "        df_composition.columns = df_composition.iloc[0]\n",
    "        \n",
    "        # delete first row\n",
    "        df_composition = df_composition.iloc[1:].fillna( method='ffill' )\n",
    "\n",
    "        #remove pocket ling, shell and lining\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Pocket lining:', '', regex = True )\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Shell:', '', regex = True )\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Lining:', '', regex = True )\n",
    "\n",
    "        #print(df_composition)\n",
    "        \n",
    "        # garantee the same number of columns\n",
    "        \n",
    "        df_composition = pd.concat( [df_pattern, df_composition], axis=0 )\n",
    "\n",
    "        #Rename columns\n",
    "        df_composition.columns = ['product_id', 'composition', 'fit', 'product_safety', 'size', 'more_sustainable_materials']\n",
    "        df_composition['product_name'] = product_name\n",
    "        df_composition['product_price'] = product_price\n",
    "\n",
    "        #Keep new columns if it shows up\n",
    "        aux = aux + df_composition.columns.tolist()\n",
    "\n",
    "        # merge data color + decomposition \n",
    "        \n",
    "        df_composition = pd.merge( df_composition, df_color, how='left', on='product_id' )\n",
    "        \n",
    "        # all products\n",
    "        df_compositions = pd.concat( [df_compositions, df_composition], axis=0 )\n",
    "\n",
    "#print(df_composition)\n",
    "# Join Showroom data + details\n",
    "df_compositions['style_id'] = df_compositions['product_id'].apply( lambda x: x[:-3] )\n",
    "df_compositions['color_id'] = df_compositions['product_id'].apply( lambda x: x[-3:] )\n",
    "# scrapy datetime\n",
    "df_compositions['scrapy_datetime'] = datetime.now().strftime( '%Y-%m-%d %H:%M:%S' )\n",
    "#df_compositions = df_compositions.drop_duplicates(subset=['style_id', 'product_id', 'color_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>composition</th>\n",
       "      <th>fit</th>\n",
       "      <th>product_safety</th>\n",
       "      <th>size</th>\n",
       "      <th>more_sustainable_materials</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>color_name</th>\n",
       "      <th>style_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0690449001</td>\n",
       "      <td>Cotton 99%, Spandex 1%</td>\n",
       "      <td>Skinny fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans</td>\n",
       "      <td>16.99</td>\n",
       "      <td>Light denim blue/trashed</td>\n",
       "      <td>0690449</td>\n",
       "      <td>001</td>\n",
       "      <td>2021-10-24 11:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0690449002</td>\n",
       "      <td>Cotton 98%, Spandex 2%</td>\n",
       "      <td>Skinny fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans</td>\n",
       "      <td>14.99</td>\n",
       "      <td>Denim blue</td>\n",
       "      <td>0690449</td>\n",
       "      <td>002</td>\n",
       "      <td>2021-10-24 11:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0690449006</td>\n",
       "      <td>Cotton 100%</td>\n",
       "      <td>Skinny fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans</td>\n",
       "      <td>7.99</td>\n",
       "      <td>Black/washed</td>\n",
       "      <td>0690449</td>\n",
       "      <td>006</td>\n",
       "      <td>2021-10-24 11:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0690449006</td>\n",
       "      <td>Cotton 98%, Spandex 2%</td>\n",
       "      <td>Skinny fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans</td>\n",
       "      <td>7.99</td>\n",
       "      <td>Black/washed</td>\n",
       "      <td>0690449</td>\n",
       "      <td>006</td>\n",
       "      <td>2021-10-24 11:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0690449007</td>\n",
       "      <td>Cotton 98%, Spandex 2%</td>\n",
       "      <td>Skinny fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans</td>\n",
       "      <td>14.99</td>\n",
       "      <td>Light denim blue</td>\n",
       "      <td>0690449</td>\n",
       "      <td>007</td>\n",
       "      <td>2021-10-24 11:53:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id             composition         fit product_safety size  \\\n",
       "0  0690449001  Cotton 99%, Spandex 1%  Skinny fit            NaN  NaN   \n",
       "0  0690449002  Cotton 98%, Spandex 2%  Skinny fit            NaN  NaN   \n",
       "0  0690449006             Cotton 100%  Skinny fit            NaN  NaN   \n",
       "1  0690449006  Cotton 98%, Spandex 2%  Skinny fit            NaN  NaN   \n",
       "0  0690449007  Cotton 98%, Spandex 2%  Skinny fit            NaN  NaN   \n",
       "\n",
       "  more_sustainable_materials                    product_name product_price  \\\n",
       "0                        NaN  \\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans         16.99   \n",
       "0                        NaN  \\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans         14.99   \n",
       "0                        NaN  \\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans          7.99   \n",
       "1                        NaN  \\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans          7.99   \n",
       "0                        NaN  \\n\\t\\t\\t\\t\\t\\t\\t  Skinny Jeans         14.99   \n",
       "\n",
       "                 color_name style_id color_id      scrapy_datetime  \n",
       "0  Light denim blue/trashed  0690449      001  2021-10-24 11:53:43  \n",
       "0                Denim blue  0690449      002  2021-10-24 11:53:43  \n",
       "0              Black/washed  0690449      006  2021-10-24 11:53:43  \n",
       "1              Black/washed  0690449      006  2021-10-24 11:53:43  \n",
       "0          Light denim blue  0690449      007  2021-10-24 11:53:43  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compositions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3.0 Data Cleaning**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 15)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # product id\n",
    "df_data = df_compositions.dropna(subset = ['product_id'])\n",
    "# # product name\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\n', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\t', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('  ', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace(' ', '_')\n",
    "df_data['product_name'] = df_data['product_name'].str.lower()\n",
    "\n",
    "# #product_price\n",
    "df_data['product_price'] = df_data['product_price'].astype( float )\n",
    "\n",
    "# color name\n",
    "df_data['color_name'] = df_data['color_name'].replace(' ', '_').str.lower()\n",
    "\n",
    "# fit\n",
    "df_data['fit'] = df_data['fit'].apply( lambda x: x.replace( ' ', '_' ).lower() if pd.notnull( x ) else x )\n",
    "\n",
    "# size number\n",
    "df_data['size_number'] = df_data['size'].apply( lambda x: re.search( '\\d{3}cm', x ).group(0) if pd.notnull( x ) else x )\n",
    "df_data['size_number'] = df_data['size_number'].apply( lambda x: re.search( '\\d+', x).group(0) if pd.notnull( x ) else x )\n",
    "\n",
    "# # # size model\n",
    "df_data['size_model'] = df_data['size'].str.extract( '(\\d+/\\\\d+)' )\n",
    "\n",
    "# ================== composition =================\n",
    "# break composition by comma\n",
    "df1 = df_data['composition'].str.split( ',', expand=True ).reset_index(drop= True)\n",
    "# cotton | polyester | elastano | elasterell\n",
    "df_ref = pd.DataFrame( index=np.arange( len( data ) ),columns=['cotton','polyester', 'elastane', 'elasterell'] )\n",
    "# ===========================cotton=====================\n",
    "df_cotton_0 = df1.loc[df1[0].str.contains('Cotton', na=True),0]\n",
    "df_cotton_0.name = 'cotton'\n",
    "\n",
    "df_cotton_1 = df1.loc[df1[1].str.contains('Cotton', na=True),1]\n",
    "df_cotton_1.name = 'cotton'\n",
    "\n",
    "#combine\n",
    "df_cotton = df_cotton_0.combine_first(df_cotton_1)\n",
    "\n",
    "df_ref = pd.concat( [df_ref, df_cotton ], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last')]\n",
    "\n",
    "#  ===================== polyester==========================\n",
    "df_polyester_0 = df1.loc[df1[0].str.contains( 'Polyester', na=True ), 0]\n",
    "df_polyester_0.name = 'polyester'\n",
    "\n",
    "df_polyester_1 = df1.loc[df1[1].str.contains( 'Polyester', na=True ), 1]\n",
    "df_polyester_1.name = 'polyester'\n",
    "\n",
    "#combine\n",
    "df_polyester = df_polyester_0.combine_first(df_polyester_1)\n",
    "df_ref = pd.concat( [df_ref, df_polyester], axis=1 )\n",
    "# df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last') ]\n",
    "# df_ref['polyester'] = df_ref['polyester'].fillna( 'Polyester 0%' )\n",
    "\n",
    "# ================= elasterell ==============\n",
    "df_elasterell = df1.loc[df1[1].str.contains( 'Elasterell', na=True ), 1]\n",
    "df_elasterell.name = 'elasterell'\n",
    "df_ref = pd.concat( [df_ref, df_elasterell], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last') ]\n",
    "\n",
    "#join of combine with product_id\n",
    "df_aux = pd.concat([df_data['product_id'].reset_index(drop=True), df_ref], axis = 1)\n",
    "\n",
    "# # format composition data\n",
    "df_aux['cotton'] = df_aux['cotton'].apply( lambda x: int( re.search( '\\d+', x ).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "df_aux['polyester'] = df_aux['polyester'].apply( lambda x: int( re.search( '\\d+', x).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "df_aux['elastane'] = df_aux['elastane'].apply( lambda x: int( re.search( '\\d+', x ).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "df_aux['elasterell'] = df_aux['elasterell'].apply( lambda x: int(re.search('\\d+',x ).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "\n",
    "# # final join\n",
    "df_aux = df_aux.groupby('product_id').max().reset_index().fillna(0)\n",
    "df_data = pd.merge(df_data, df_aux, how = 'left', on = 'product_id')\n",
    " # Drop columns\n",
    "df_data = df_data.drop( columns=['size', 'product_safety', 'composition'], axis=1 )\n",
    "# # Drop duplicates\n",
    "df_data = df_data.drop_duplicates()\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "197781329f61db6e639ec96e980a76affcc5932ce7d8264ae77a029244a76227"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
