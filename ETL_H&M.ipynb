{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.0 Data Scrapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "#Encontrando o html dos produtos\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "products = soup.find('ul', class_ = 'products-listing small')\n",
    "products_list = products.find_all('article', class_= 'hm-product-item')\n",
    "\n",
    "\n",
    "#Product id\n",
    "product_id = [p.get('data-articlecode') for p in products_list]\n",
    "\n",
    "\n",
    "#Product Category\n",
    "product_category = [p.get('data-category') for p in products_list]\n",
    "\n",
    "#Product name\n",
    "products_list = products.find_all('a', class_= 'link')\n",
    "product_name = [p.get_text() for p in products_list]\n",
    "\n",
    "#Price\n",
    "price_list = products.find_all('span', class_= 'price regular')\n",
    "product_price = [ p.get_text() for p in price_list]\n",
    "product_price\n",
    "\n",
    "data = pd.DataFrame([product_id, product_category, product_name,  product_price]).T\n",
    "data.columns = ['product_id', 'product_category', 'product_name', 'product_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.0 Data Collection by Product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "# empty dataframe\n",
    "df_details = pd.DataFrame()\n",
    "# unique columns for all products\n",
    "aux = []\n",
    "cols = ['Art. No.', 'Composition', 'Fit', 'Product safety', 'Size']\n",
    "df_compositions = pd.DataFrame( columns=cols )\n",
    "for i in range( len( data ) ):\n",
    "    \n",
    "    # API Requests\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id']+ '.html'\n",
    "    page = requests.get( url, headers=headers )\n",
    "    \n",
    "    # Beautiful Soup object\n",
    "    soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "    \n",
    "    # ==================== color name =================================\n",
    "    product_list = soup.find_all( 'a', class_='filter-option miniature' ) soup.find_all( 'a', class_='filter-option miniature-active' )\n",
    "    color_name = [p.get( 'data-color' ) for p in product_list]\n",
    "    \n",
    "    \n",
    "    # product id\n",
    "    product_id = [p.get( 'data-articlecode' ) for p in product_list]\n",
    "    df_color = pd.DataFrame( [product_id, color_name] ).T\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "    \n",
    "    \n",
    "    # generate style id + color id\n",
    "    df_color['style_id'] = df_color['product_id'].apply( lambda x: x[:-3] )\n",
    "    df_color['color_id'] = df_color['product_id'].apply( lambda x: x[-3:] )\n",
    "    \n",
    "    # ==================== composition =================================\n",
    "    product_composition_list = soup.find_all( 'div', class_='pdp-description-list-item' )\n",
    "    product_composition = [list( filter( None, p.get_text().split( '\\n' ) ) ) for p in product_composition_list]\n",
    "    \n",
    "    # rename dataframe\n",
    "    df_composition = pd.DataFrame( product_composition ).T\n",
    "    df_composition.columns = df_composition.iloc[0]\n",
    "    \n",
    "    # delete first row\n",
    "    df_composition = df_composition.iloc[1:].fillna( method='ffill' )\n",
    "\n",
    "    #remove pocket ling, shell and lining\n",
    "    df_composition['Composition'] = df_composition['Composition'].replace('Pocket lining:', '', regex = True )\n",
    "    df_composition['Composition'] = df_composition['Composition'].replace('Shell:', '', regex = True )\n",
    "    df_composition['Composition'] = df_composition['Composition'].replace('Lining:', '', regex = True )\n",
    "    \n",
    "    # garantee the same number of columns\n",
    "    df_composition = pd.concat( [df_pattern, df_composition], axis=0 )\n",
    "\n",
    "    #Rename columns\n",
    "    df_composition.columns = ['product_id', 'composition', 'fit', 'product_safety', 'size']\n",
    "\n",
    "    # generate style id + color id\n",
    "    #df_composition['style_id'] = df_composition['Art. No.'].apply( lambda x: x[:-3] )\n",
    "    #df_composition['color_id'] = df_composition['Art. No.'].apply( lambda x: x[-3:] )\n",
    "    \n",
    "    #Keep new columns if it shows up\n",
    "    aux = aux + df_composition.columns.tolist()\n",
    "\n",
    "    # merge data color + decomposition \n",
    "    \n",
    "    df_composition = pd.merge( df_composition, df_color, how='left', on='product_id' )\n",
    "    \n",
    "    # all details products\n",
    "    df_compositions = pd.concat( [df_compositions, df_composition], axis=0 )\n",
    "\n",
    "    \n",
    "    # Join Showroom data + details\n",
    "    # data['style_id'] = data['product_id'].apply( lambda x: x[:-3] )\n",
    "    # data['color_id'] = data['product_id'].apply( lambda x: x[-3:] )\n",
    "    # data_raw = pd.merge( data, df_details[['style_id', 'color_name', 'Fit','Composition', 'Size', 'Product safety']], \n",
    "    #                     how='left', on='style_id' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3.0 Data Cleaning**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('product_hm.csv')\n",
    "data = data.drop(columns = ['Unnamed: 0'])\n",
    "# product id\n",
    "data = data.dropna( subset=['product_id'] )\n",
    "data['product_id'] = data['product_id'].astype( int )\n",
    "\n",
    "# product name\n",
    "#data['product_name'] = data['product_name'].apply( lambda x: x.replace( ' ' '_' ).lower() \n",
    "\n",
    "data['Price'] = data['Price'].apply( lambda x: x.replace( '$ ','' ) ).astype( float )\n",
    "\n",
    "# style id\n",
    "data['style_id'] = data['style_id'].astype( int )\n",
    "\n",
    "# color id\n",
    "data['color_id'] = data['color_id'].astype( int )\n",
    "\n",
    "# color name\n",
    "#data['color_name'] = data['color_name'].apply( lambda x: x.replace( ' ', '_' ).replace( '/', '_' ).lower() if pd.notnull( x ) else x )\n",
    "\n",
    "# fit\n",
    "data['Fit'] = data['Fit'].apply( lambda x: x.replace( ' ', '_' ).lower() if pd.notnull( x ) else x )\n",
    "\n",
    "# size number\n",
    "data['size_number'] = data['Size'].apply( lambda x: re.search( '\\d{3}cm', x ).group(0) if pd.notnull( x ) else x )\n",
    "data['size_number'] = data['size_number'].apply( lambda x: re.search( '\\d+', x).group(0) if pd.notnull( x ) else x )\n",
    "\n",
    "# size model\n",
    "data['size_model'] = data['Size'].str.extract( '(\\d+/\\\\d+)' )\n",
    "# composition\n",
    "data = data[~data['Composition'].str.contains( 'Pocket lining:', na=False )]\n",
    "data = data[~data['Composition'].str.contains( 'Lining:', na=False )]\n",
    "data = data[~data['Composition'].str.contains( 'Shell:', na=False )]\n",
    "\n",
    "# drop duplicates\n",
    "data = data.drop_duplicates( subset=['product_id', 'product_category', 'Price','scrapy_datetime', 'style_id', 'color_id','color_name', 'Fit'], keep='last' )\n",
    "\n",
    "# reset index\n",
    "data = data.reset_index( drop=True )\n",
    "# break composition by comma\n",
    "df1 = data['Composition'].str.split( ',', expand=True )\n",
    "# cotton | polyester | elastano | elasterell\n",
    "df_ref = pd.DataFrame( index=np.arange( len( data ) ),columns=['cotton','polyester', 'elastane', 'elasterell'] )\n",
    "# cotton\n",
    "df_cotton = df1[0]\n",
    "df_cotton.name = 'cotton'\n",
    "df_ref = pd.concat( [df_ref, df_cotton ], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last')]\n",
    "df_ref['cotton'] = df_ref['cotton'].fillna( 'Cotton 0%' )\n",
    "# polyester\n",
    "df_polyester = df1.loc[df1[1].str.contains( 'Polyester', na=True ), 1]\n",
    "df_polyester.name = 'polyester'\n",
    "df_ref = pd.concat( [df_ref, df_polyester], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last') ]\n",
    "df_ref['polyester'] = df_ref['polyester'].fillna( 'Polyester 0%' )\n",
    "# elastano\n",
    "df_elastane = df1.loc[df1[1].str.contains( 'Elastane', na=True ), 1]\n",
    "df_elastane.name = 'elastane'\n",
    "# combine elastane from both columns 1 and 2\n",
    "df_elastane = df_elastane.combine_first( df1[2] )\n",
    "\n",
    "df_ref = pd.concat( [df_ref, df_elastane], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last') ]\n",
    "df_ref['elastane'] = df_ref['elastane'].fillna( 'Elastane 0%' )\n",
    "# elasterell\n",
    "df_elasterell = df1.loc[df1[1].str.contains( 'Elasterell', na=True ), 1]\n",
    "df_elasterell.name = 'elasterell'\n",
    "df_ref = pd.concat( [df_ref, df_elasterell], axis=1 )\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated( keep='last') ]\n",
    "df_ref['elasterell'] = df_ref['elasterell'].fillna( 'Elasterell-P 0%' )\n",
    "# final join\n",
    "data = pd.concat( [data, df_ref], axis=1 )\n",
    "# format composition data\n",
    "data['cotton'] = data['cotton'].apply( lambda x: int( re.search( '\\d+', x ).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "data['polyester'] = data['polyester'].apply( lambda x: int( re.search( '\\d+', x).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "data['elastane'] = data['elastane'].apply( lambda x: int( re.search( '\\d+', x ).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "data['elasterell'] = data['elasterell'].apply( lambda x: int(re.search('\\d+',x ).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "# Drop columns\n",
    "data = data.drop( columns=['Size', 'Product safety', 'Composition'], axis=1 )\n",
    "# Drop duplicates\n",
    "data = data.drop_duplicates()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "197781329f61db6e639ec96e980a76affcc5932ce7d8264ae77a029244a76227"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
